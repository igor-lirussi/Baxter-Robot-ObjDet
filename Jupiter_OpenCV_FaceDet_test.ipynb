{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests for Face detection with OpenCV\n",
    "the following notebook contains some test with different model/images for face detection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV: 4.5.3\n",
      "IMPORTS OK\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "print(\"OpenCV: \"+ str(cv2.__version__))\n",
    "print(\"IMPORTS OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"./img/faces.png\"\n",
    "show_image = False #show preview image in notebook\n",
    "WIDTH_ROBOT = 960\n",
    "HEIGHT_ROBOT = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimensions image upload: (600, 960)\n",
      "dimensions robot camera: (600, 960)\n",
      "Same dimensions: True\n"
     ]
    }
   ],
   "source": [
    "#Read image\n",
    "img_original = cv2.imread(image_path,cv2.IMREAD_COLOR )\n",
    "#calculate h and w\n",
    "(h, w) = img_original.shape[:2]\n",
    "WIDTH = w\n",
    "HEIGHT = h\n",
    "print(\"dimensions image upload: \"+ str((h,w)) )\n",
    "print(\"dimensions robot camera: \"+ str((HEIGHT_ROBOT, WIDTH_ROBOT)) )\n",
    "print(\"Same dimensions: \"+str((h,w)==(HEIGHT, WIDTH)))\n",
    "\n",
    "def imshow(image_passed, save=False):\n",
    "    if show_image:\n",
    "        #cv2.imshow(\"image\",image_passed) #not working in Jupiter notebook\n",
    "        plt.imshow(cv2.cvtColor(image_passed, cv2.COLOR_BGR2RGB))\n",
    "        plt.show()\n",
    "    if save:\n",
    "        #SAVE\n",
    "        cv2.imwrite(\"./img/save.png\",image_passed)\n",
    "        print(\"Saved\")\n",
    "\n",
    "#SHOW IMAGE        \n",
    "imshow(img_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HAAR CLASSIFIER FACE DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Loaded\n"
     ]
    }
   ],
   "source": [
    "#Load Classifier\n",
    "CASC_PATH = \"./models/haarcascade_frontalface_default.xml\"\n",
    "face_cascade = cv2.CascadeClassifier(CASC_PATH)\n",
    "print(\"Classifier Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected: 15\n",
      "Saved\n"
     ]
    }
   ],
   "source": [
    "img_haar = img_original.copy() #copy img\n",
    "\n",
    "#SHOW IMAGE        \n",
    "imshow(img_haar)\n",
    "\n",
    "#FORWARD\n",
    "faces = face_cascade.detectMultiScale(img_haar, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "#print(\"faces detected: \",faces.shape[0])\n",
    "print(\"Detected: \"+str(len(faces)))\n",
    "\n",
    "#draw bounding boxes\n",
    "for face in faces:\n",
    "    x, y, w, h = face\n",
    "    cv2.rectangle(img_haar, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "#SHOW IMAGE        \n",
    "imshow(img_haar, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DLIB (HOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Loaded\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import dlib  #requires pip install dlib\n",
    "#Load Classifier\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "print(\"Classifier Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected: 18\n",
      "Saved\n"
     ]
    }
   ],
   "source": [
    "img_dlib = img_original.copy() #copy img\n",
    "\n",
    "#SHOW IMAGE        \n",
    "imshow(img_dlib)\n",
    "\n",
    "#FORWARD\n",
    "gray = cv2.cvtColor(img_dlib, cv2.COLOR_BGR2GRAY)\n",
    "faces = detector(gray, 1) # result\n",
    "print(\"Detected: \"+str(len(faces)))\n",
    "\n",
    "#to draw faces on image\n",
    "for result in faces:\n",
    "    x1 = result.left()\n",
    "    y1 = result.top()\n",
    "    x2 = result.right()\n",
    "    y2 = result.bottom()\n",
    "    cv2.rectangle(img_dlib, (x1, y1), (x2, y2), (0,255 , 0), 2)\n",
    "    \n",
    "\n",
    "#SHOW IMAGE        \n",
    "imshow(img_dlib, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN FACE DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net Loaded\n"
     ]
    }
   ],
   "source": [
    "#Load net\n",
    "PROTO = \"./models/res10_deploy.prototxt\"\n",
    "MODEL = \"./models/res10_300x300_ssd_iter_140000_fp16.caffemodel\"\n",
    "net = cv2.dnn.readNetFromCaffe(PROTO, MODEL)\n",
    "print(\"Net Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected: 200\n",
      "Detected: 14 (after threshold)\n",
      "Saved\n"
     ]
    }
   ],
   "source": [
    "img_dnn = img_original.copy() #copy img\n",
    "\n",
    "#SHOW IMAGE        \n",
    "imshow(img_dnn)\n",
    "\n",
    "#FORWARD image\n",
    "#blob = cv2.dnn.blobFromImage(cv2.resize(img_dnn, (300, 300)), 1.0, (300, 300), (104.0, 117.0, 123.0))\n",
    "blob = cv2.dnn.blobFromImage(img_dnn, 1.0, (300, 300), [104, 117, 123], False, False)\n",
    "net.setInput(blob)\n",
    "detections = net.forward()\n",
    "print(\"Detected: \" + str(detections.shape[2]))\n",
    "detected_after_threshold=0\n",
    "\n",
    "#draw bounding box\n",
    "conf_threshold=0.15\n",
    "bboxes = []\n",
    "for i in range(detections.shape[2]):\n",
    "    confidence = detections[0, 0, i, 2]\n",
    "    if confidence > conf_threshold:\n",
    "        detected_after_threshold+=1\n",
    "        x1 = int(detections[0, 0, i, 3] * WIDTH)\n",
    "        y1 = int(detections[0, 0, i, 4] * HEIGHT)\n",
    "        x2 = int(detections[0, 0, i, 5] * WIDTH)\n",
    "        y2 = int(detections[0, 0, i, 6] * HEIGHT)\n",
    "        cv2.rectangle(img_dnn, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "print(\"Detected: \" + str(detected_after_threshold) + \" (after threshold)\")\n",
    "\n",
    "\n",
    "#SHOW IMAGE        \n",
    "imshow(img_dnn, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCV FaceDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net Loaded\n"
     ]
    }
   ],
   "source": [
    "#Load net\n",
    "CONFIG = \"./models/opencv_face_detector.pbtxt\"\n",
    "MODEL = \"./models/opencv_face_detector_uint8.pb\"\n",
    "net = cv2.dnn.readNetFromTensorflow(MODEL, CONFIG)\n",
    "print(\"Net Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected: 200\n",
      "Detected: 1 (after threshold)\n",
      "Saved\n"
     ]
    }
   ],
   "source": [
    "img_cvdet = img_original.copy() #copy img\n",
    "\n",
    "#SHOW IMAGE        \n",
    "imshow(img_cvdet)\n",
    "\n",
    "#FORWARD image\n",
    "blob = cv2.dnn.blobFromImage(img_cvdet, 1.0, (300, 300), [104, 117, 123], True, False)\n",
    "net.setInput(blob)\n",
    "detections = net.forward()\n",
    "print(\"Detected: \" + str(detections.shape[2]))\n",
    "detected_after_threshold=0\n",
    "\n",
    "#draw bounding box\n",
    "conf_threshold=0.15\n",
    "bboxes = []\n",
    "for i in range(detections.shape[2]):\n",
    "    confidence = detections[0, 0, i, 2]\n",
    "    if confidence > conf_threshold:\n",
    "        detected_after_threshold+=1\n",
    "        x1 = int(detections[0, 0, i, 3] * WIDTH)\n",
    "        y1 = int(detections[0, 0, i, 4] * HEIGHT)\n",
    "        x2 = int(detections[0, 0, i, 5] * WIDTH)\n",
    "        y2 = int(detections[0, 0, i, 6] * HEIGHT)\n",
    "        bboxes.append([x1, y1, x2, y2])\n",
    "        cv2.rectangle(img_cvdet, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "print(\"Detected: \" + str(detected_after_threshold) + \" (after threshold)\")\n",
    "\n",
    "\n",
    "#SHOW IMAGE        \n",
    "imshow(img_cvdet, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
